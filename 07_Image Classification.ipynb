{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1-Introduction\" data-toc-modified-id=\"1-Introduction-1\">1 Introduction</a></span></li><li><span><a href=\"#2-Functions-for-classifying-images\" data-toc-modified-id=\"2-Functions-for-classifying-images-2\">2 Functions for classifying images</a></span></li><li><span><a href=\"#3-Data-Processing\" data-toc-modified-id=\"3-Data-Processing-3\">3 Data Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Image-classification-of-Funil-(time-series)\" data-toc-modified-id=\"3.1-Image-classification-of-Funil-(time-series)-3.1\">3.1 Image classification of Funil (time series)</a></span></li><li><span><a href=\"#3.2-Image-classification-of-Curuai-lake-(time-series)\" data-toc-modified-id=\"3.2-Image-classification-of-Curuai-lake-(time-series)-3.2\">3.2 Image classification of Curuai lake (time series)</a></span></li><li><span><a href=\"#3.3-Image-classification-of-ECP-(novelty-assessment)\" data-toc-modified-id=\"3.3-Image-classification-of-ECP-(novelty-assessment)-3.3\">3.3 Image classification of ECP (novelty assessment)</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.3.1-Without-using-probability\" data-toc-modified-id=\"3.3.1-Without-using-probability-3.3.1\">3.3.1 Without using probability</a></span></li><li><span><a href=\"#3.3.2-Using-probability-excluding-the-lowest-1%-values\" data-toc-modified-id=\"3.3.2-Using-probability-excluding-the-lowest-1%-values-3.3.2\">3.3.2 Using probability excluding the lowest 1% values</a></span></li><li><span><a href=\"#3.3.3-Retrieve-prob-values\" data-toc-modified-id=\"3.3.3-Retrieve-prob-values-3.3.3\">3.3.3 Retrieve prob values</a></span></li></ul></li><li><span><a href=\"#3.4-Image-classification-of-Funil-(novelty-assessment)\" data-toc-modified-id=\"3.4-Image-classification-of-Funil-(novelty-assessment)-3.4\">3.4 Image classification of Funil (novelty assessment)</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.1-Without-using-probability\" data-toc-modified-id=\"3.4.1-Without-using-probability-3.4.1\">3.4.1 Without using probability</a></span></li><li><span><a href=\"#3.4.2-Using-probability-excluding-the-lowest-1%-values\" data-toc-modified-id=\"3.4.2-Using-probability-excluding-the-lowest-1%-values-3.4.2\">3.4.2 Using probability excluding the lowest 1% values</a></span></li><li><span><a href=\"#3.4.3-Retrieve-prob-values\" data-toc-modified-id=\"3.4.3-Retrieve-prob-values-3.4.3\">3.4.3 Retrieve prob values</a></span></li></ul></li><li><span><a href=\"#3.5-Image-classification-of-Curuai-lake-(novelty-assessment)\" data-toc-modified-id=\"3.5-Image-classification-of-Curuai-lake-(novelty-assessment)-3.5\">3.5 Image classification of Curuai lake (novelty assessment)</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.5.1-Without-using-probability\" data-toc-modified-id=\"3.5.1-Without-using-probability-3.5.1\">3.5.1 Without using probability</a></span></li><li><span><a href=\"#3.5.2-Using-probability-excluding-the-lowest-1%-values\" data-toc-modified-id=\"3.5.2-Using-probability-excluding-the-lowest-1%-values-3.5.2\">3.5.2 Using probability excluding the lowest 1% values</a></span></li><li><span><a href=\"#3.5.3-Retrieve-prob-value\" data-toc-modified-id=\"3.5.3-Retrieve-prob-value-3.5.3\">3.5.3 Retrieve prob value</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction\n",
    "<br>\n",
    "This notebook classify the examples images to shown the algorithm classification of Sentinel-2 MSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Functions for classifying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library used\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import *\n",
    "import os\n",
    "def image_to_arrays(image):\n",
    "    '''\n",
    "    This function read the output image from atmopheric correction and deglint, which\n",
    "    have the following structure bands:\n",
    "    0: B2\n",
    "    1: B3\n",
    "    2: B4\n",
    "    3: B5\n",
    "    4: B6\n",
    "    Then, it returns the arrays of all bands.\n",
    "    -----------------------\n",
    "    image(str): image path\n",
    "    -----------------------\n",
    "    return: the five bands necessary for the OWT classification.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # read image\n",
    "    image =  gdal.Open(image, GA_ReadOnly)\n",
    "    \n",
    "    # read arrays\n",
    "    bandas = image.ReadAsArray()\n",
    "\n",
    "    # band selection\n",
    "    b2 = bandas[0]\n",
    "    b3 = bandas[1]\n",
    "    b4 = bandas[2]\n",
    "    b5 = bandas[3]\n",
    "    b6 = bandas[4]\n",
    "\n",
    "\n",
    "    return b2, b3, b4, b5, b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "def SVMC_image_classification(b2, b3, b4, b5, b6,\n",
    "                              alg_path='00_Database/02_Algorithms/msi_svmc_owts_alldataset.obj',\n",
    "                              novelty=False,\n",
    "                              retrieve_prob=False,\n",
    "                              msisvcprob={'OWT 1': 72,\n",
    "                                          'OWT 2': 56,\n",
    "                                          'OWT 3': 30,\n",
    "                                          'OWT 4': 35,\n",
    "                                          'OWT 5': 56,\n",
    "                                          'OWT 6': 50,\n",
    "                                          'OWT 7': 74,\n",
    "                                          'OWT 8': 50}):\n",
    "    '''\n",
    "    This function utilize the Support Vector Machine Classification (SVMC) built on\n",
    "    Scikit-learn for classifying arrays extracted from Sentinel-2 images.\n",
    "    -------------------------\n",
    "    b2 (np.array): Remote sensing reflectance (Rrs) of B2 band.\n",
    "    b3 (np.array): Rrs of B3 band.\n",
    "    b4 (np.array): Rrs of B4 band.\n",
    "    b5 (np.array): Rrs of B5 band.\n",
    "    b6 (np.array): Rrs of B6 band.\n",
    "    alg_path (str): Algorithm path for the list with shape and intensity classification.\n",
    "    novelty (boolean): Use probability estimations for detectin novel OWT based on specific thresholds. \n",
    "    retrieve_prob (boolean): Retrieve the map of progability values instead of OWTs.\n",
    "    --------------------------\n",
    "    return a classified array\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Open the SVMC algorithm\n",
    "    msi_svmc_alg = open(alg_path, 'rb') \n",
    "    msi_svmc_alg = pickle.load(msi_svmc_alg)\n",
    "    model = msi_svmc_alg[0]\n",
    "    modelint = msi_svmc_alg[1]\n",
    "    \n",
    "    # normalize bands by its sum\n",
    "    bandasoma = b2+b3+b4+b5+b6\n",
    "    bandasoma[bandasoma==0] = -32 # 0 values crashes the division\n",
    "    b2norm = b2 / bandasoma\n",
    "    b2 = None # dump cache\n",
    "    b3norm = b3 / bandasoma\n",
    "    b4norm = b4 / bandasoma\n",
    "    b4 = None # dump cache\n",
    "    b5norm = b5 / bandasoma\n",
    "    b5 = None # dump cache\n",
    "    b6norm = b6 / bandasoma\n",
    "    b6 = None # dump cache\n",
    "    bandasoma = None # dump cache\n",
    "    \n",
    "    # negative values are removed because they may crash the classifications\n",
    "    b2norm[b2norm<0] = 0\n",
    "    b3norm[b3norm<0] = 0\n",
    "    b4norm[b4norm<0] = 0\n",
    "    b5norm[b5norm<0] = 0\n",
    "    b6norm[b6norm<0] = 0\n",
    "    b3[b3<0] = 0\n",
    "\n",
    "    # reshape array to 1d (needed for the scikit-learn algorithm)\n",
    "    d2shape = (b5norm.shape[0], b5norm.shape[1])\n",
    "    d1shape = b5norm.size\n",
    "    b2norm1d = b2norm.reshape(d1shape)\n",
    "    b3norm1d = b3norm.reshape(d1shape)\n",
    "    b4norm1d = b4norm.reshape(d1shape)\n",
    "    b5norm1d = b5norm.reshape(d1shape)\n",
    "    b6norm1d = b6norm.reshape(d1shape)\n",
    "    b31d = b3.reshape(d1shape)\n",
    "    threeband1d = np.vstack([b2norm1d, b3norm1d, b4norm1d, b5norm1d, b6norm1d, b31d]).transpose()\n",
    "    threeband1d = pd.DataFrame(threeband1d)\n",
    "    \n",
    "    b2norm1d = None\n",
    "    b3norm1d = None\n",
    "    b4norm1d = None\n",
    "    b5norm1d = None\n",
    "    b6norm1d = None\n",
    "    b31d = None\n",
    "    b2norm = None # dump chache\n",
    "    b3norm = None # dump chache\n",
    "    b4norm = None # dump chache\n",
    "    b5norm = None # dump chache\n",
    "    b6norm = None # dump chache\n",
    "    b3 = None # dump chache\n",
    "    \n",
    "    # drop values below 0 (mask) to speed up classification\n",
    "    target = threeband1d[threeband1d>0].dropna()\n",
    "    \n",
    "    # classification\n",
    "    # 1 shape classification\n",
    "    predicted = model.predict(target.iloc[:,0:-1])\n",
    "    predicted = pd.DataFrame(predicted,\n",
    "                             index=target.index,\n",
    "                             columns=['predicted'])\n",
    "    if novelty == True:\n",
    "        prob = pd.DataFrame(model.predict_proba(target.iloc[:,0:-1]),\n",
    "                            index=target.index,\n",
    "                            columns=model.classes_)\n",
    "        predicted = predicted.join(prob)\n",
    "        prob = None\n",
    "    \n",
    "    # 2 intensity classification\n",
    "    owt789id = predicted[predicted['predicted'] == 'OWT 678'].index\n",
    "    predicteddt = modelint.predict(target.iloc[:,-1:].loc[owt789id,:].values)\n",
    "    predicteddt = pd.DataFrame(predicteddt,\n",
    "                               index=owt789id,\n",
    "                               columns=['predicted'])\n",
    "    if novelty == True:\n",
    "        predicteddtprob = pd.DataFrame(modelint.predict_proba(target.iloc[:,-1:].loc[owt789id,:].values),\n",
    "                                       index=owt789id,\n",
    "                                       columns=modelint.classes_)\n",
    "        predicteddtprob = predicteddtprob.multiply(predicted['OWT 678'], axis=0).dropna(axis=0, how='all')\n",
    "        predicteddt = predicteddt.join(predicteddtprob)\n",
    "        predicteddtprob = None\n",
    "    \n",
    "    # Concat shape and intensity classification\n",
    "    predicted.update(predicteddt)\n",
    "    if novelty == True:\n",
    "        predicted = predicted.join(predicteddt.iloc[:,1:])\n",
    "        predicted = predicted.drop('OWT 678', axis=1)\n",
    "        \n",
    "    predicteddt = None\n",
    "    predicteddtprob = None\n",
    "    \n",
    "    # classify as novel the predictions with lower probability than the threshold set\n",
    "    if novelty == True and retrieve_prob==False:\n",
    "        \n",
    "        for x in predicted.columns[1:]:\n",
    "\n",
    "            try:\n",
    "                id_to_drop = predicted[(predicted[x] < msisvcprob[x]/100) & (predicted['predicted'] == x)].index\n",
    "                predicted.loc[id_to_drop, 'predicted'] = np.nan\n",
    "            \n",
    "            except:\n",
    "                print('Novelty detection failed to: ', x)\n",
    "                print('Probably, this OWT does not occur in the image')\n",
    "\n",
    "    elif novelty == True and retrieve_prob==True:\n",
    "        \n",
    "        predicted = predicted.max(axis=1)*100\n",
    "        predicted.name = 'predicted'\n",
    "    if retrieve_prob==False:\n",
    "        \n",
    "        # replace OWTs names by numbers, for saving in a tiff file\n",
    "        predicted = predicted.replace(['OWT 1', 'OWT 2', 'OWT 3', 'OWT 4','OWT 5', 'OWT 6', 'OWT 7','OWT 8', 'OWT 9'],\n",
    "                                      [1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    \n",
    "    # generate the 2D array classification\n",
    "    threeband1d = threeband1d.join(predicted)\n",
    "    classified = threeband1d['predicted'].values.reshape(d2shape)\n",
    "    \n",
    "    return classified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library used\n",
    "from osgeo import gdal\n",
    "\n",
    "def array_to_image(classified, i, path, geotransform, projection):\n",
    "    '''\n",
    "    This function convert a array to tiff\n",
    "    -----------------------------\n",
    "    classified (np.array): an image array.\n",
    "    i (str): image name.\n",
    "    path: path for saving the tiff image.\n",
    "    geotransform: Geotransform for saving the image (e.g.: image.GetGeoTransform()).\n",
    "    projection: Projection for saving the image (e.g.: image.GetProjection())\n",
    "    '''   \n",
    "    # save results\n",
    "    # set image dimensions\n",
    "    image_size = classified.shape\n",
    "    nx = image_size[0]\n",
    "    ny = image_size[1]\n",
    "\n",
    "    # create the classified raster file\n",
    "    dst_ds = gdal.GetDriverByName('GTiff').Create(path+'/'+i+'_owt.tif', ny, nx, 1, gdal.GDT_Int16)\n",
    "\n",
    "    dst_ds.SetGeoTransform(geotransform)    # specify coords\n",
    "    dst_ds.SetProjection(projection) # export coords to file       \n",
    "    dst_ds.GetRasterBand(1).WriteArray(classified)   # write r-band to the raster\n",
    "    dst_ds.GetRasterBand(1).SetNoDataValue(0) \n",
    "    dst_ds.FlushCache()                     # write to disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Image classification of Funil (time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "import glob\n",
    "\n",
    "# add path with bands and folder to save images\n",
    "path = '00_Database/03_Images/03_Funil/l2/'\n",
    "owt_path = '00_Database/03_Images/03_Funil/l3_owts'\n",
    "\n",
    "for img in glob.glob(path+'*.tif'):\n",
    "    \n",
    "    b2, b3, b4, b5, b6 = image_to_arrays(img)\n",
    "    b2 = b2*0.0001\n",
    "    b3 = b3*0.0001\n",
    "    b4 = b4*0.0001\n",
    "    b5 = b5*0.0001\n",
    "    b6 = b6*0.0001\n",
    "    img_shape = b3.shape\n",
    "\n",
    "    # split arrays for reduce memory usage in the classification\n",
    "    b2 = np.split(b2,10)\n",
    "    b3 = np.split(b3,10)\n",
    "    b4 = np.split(b4,10)\n",
    "    b5 = np.split(b5,10)\n",
    "    b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "    # image classification\n",
    "    owt_image = {}\n",
    "    for x in range(0,10):\n",
    "        owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                              b3[x],\n",
    "                                              b4[x],\n",
    "                                              b5[x],\n",
    "                                              b6[x], novelty=True)\n",
    "\n",
    "        owt_image[x] = owt_chunck\n",
    "        owt_chunck = None\n",
    "\n",
    "    owt_image = np.concatenate((owt_image[0],\n",
    "                                owt_image[1],\n",
    "                                owt_image[2],\n",
    "                                owt_image[3],\n",
    "                                owt_image[4],\n",
    "                                owt_image[5],\n",
    "                                owt_image[6],\n",
    "                                owt_image[7],\n",
    "                                owt_image[8],\n",
    "                                owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "    img_ref = gdal.Open(img, GA_ReadOnly)\n",
    "\n",
    "    geotransform = img_ref.GetGeoTransform()\n",
    "    proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "    array_to_image(owt_image,\n",
    "                   img.split('/')[-1].split('.')[0].split('B2')[0],\n",
    "                   owt_path,\n",
    "                   geotransform,\n",
    "                   proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Image classification of Curuai lake (time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path with bands and folder to save images\n",
    "path = '00_Database/03_Images/04_Curuai/l2/'\n",
    "owt_path = '00_Database/03_Images/04_Curuai/l3_owts'\n",
    "\n",
    "for img in glob.glob(path+'*.tif'):\n",
    "    \n",
    "    b2, b3, b4, b5, b6 = image_to_arrays(img)\n",
    "    b2 = b2*0.0001\n",
    "    b3 = b3*0.0001\n",
    "    b4 = b4*0.0001\n",
    "    b5 = b5*0.0001\n",
    "    b6 = b6*0.0001\n",
    "    img_shape = b3.shape\n",
    "\n",
    "    # split arrays for reduce memory usage in the classification\n",
    "    b2 = np.split(b2,10)\n",
    "    b3 = np.split(b3,10)\n",
    "    b4 = np.split(b4,10)\n",
    "    b5 = np.split(b5,10)\n",
    "    b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "    # image classification\n",
    "    owt_image = {}\n",
    "    for x in range(0,10):\n",
    "        owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                              b3[x],\n",
    "                                              b4[x],\n",
    "                                              b5[x],\n",
    "                                              b6[x], novelty=True)\n",
    "\n",
    "        owt_image[x] = owt_chunck\n",
    "        owt_chunck = None\n",
    "\n",
    "    owt_image = np.concatenate((owt_image[0],\n",
    "                                owt_image[1],\n",
    "                                owt_image[2],\n",
    "                                owt_image[3],\n",
    "                                owt_image[4],\n",
    "                                owt_image[5],\n",
    "                                owt_image[6],\n",
    "                                owt_image[7],\n",
    "                                owt_image[8],\n",
    "                                owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "    img_ref = gdal.Open(img, GA_ReadOnly)\n",
    "\n",
    "    geotransform = img_ref.GetGeoTransform()\n",
    "    proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "    array_to_image(owt_image,\n",
    "                   img.split('/')[-1].split('.')[0].split('B2')[0],\n",
    "                   owt_path,\n",
    "                   geotransform,\n",
    "                   proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Image classification of ECP (novelty assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Without using probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/02_ECP'\n",
    "img = 'T22JGS_20190724T132241B2B3B4B5b6.tif'\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x], novelty=False)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0]+'_withoutnovelty',\n",
    "               path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Using probability excluding the lowest 1% values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/02_ECP'\n",
    "img = 'T22JGS_20190724T132241B2B3B4B5b6.tif'\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x], novelty=True)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0],\n",
    "               path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Retrieve prob values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/02_ECP'\n",
    "img = 'T22JGS_20190724T132241B2B3B4B5b6.tif'\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x],\n",
    "                                           novelty=True,\n",
    "                                          retrieve_prob=True)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0]+'_owtprobvalues',\n",
    "               path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Image classification of Funil (novelty assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Without using probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/03_Funil/l2'\n",
    "img = 'T23KNR_20180820T131239B2B3B4B5b6.tif'\n",
    "owt_path = '00_Database/03_Images/03_Funil/l3_owts_without_novelty'\n",
    "\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x], novelty=False)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0]+'_withoutnovelty',\n",
    "               owt_path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Using probability excluding the lowest 1% values\n",
    "<br>\n",
    "This was already done in the 3.1 section. Thus, the same image is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Retrieve prob values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/03_Funil/l2'\n",
    "img = 'T23KNR_20180820T131239B2B3B4B5b6.tif'\n",
    "owt_path = '00_Database/03_Images/03_Funil/l3_owts_without_novelty'\n",
    "\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x],\n",
    "                                           novelty=True,\n",
    "                                          retrieve_prob=True)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0]+'owt_prob_values.tif',\n",
    "               owt_path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Image classification of Curuai lake (novelty assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Without using probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/04_Curuai/l2'\n",
    "img = 'T21MXT_20190818T141051B2B3B4B5b6.tif'\n",
    "owt_path = '00_Database/03_Images/04_Curuai/l3_owts_without_novelty'\n",
    "\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x], novelty=False)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0]+'owt.tif',\n",
    "               owt_path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Using probability excluding the lowest 1% values\n",
    "<br>\n",
    "This was already done in the 3.2 section. Thus, the same image is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Retrieve prob value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path and image name\n",
    "path = '00_Database/03_Images/04_Curuai/l2'\n",
    "img = 'T21MXT_20190818T141051B2B3B4B5b6.tif'\n",
    "owt_path = '00_Database/03_Images/04_Curuai/l3_owts_without_novelty'\n",
    "\n",
    "b2, b3, b4, b5, b6 = image_to_arrays(path+'/'+img)\n",
    "b2 = b2*0.0001\n",
    "b3 = b3*0.0001\n",
    "b4 = b4*0.0001\n",
    "b5 = b5*0.0001\n",
    "b6 = b6*0.0001\n",
    "img_shape = b3.shape\n",
    "\n",
    "# split arrays for reduce memory usage in the classification\n",
    "b2 = np.split(b2,10)\n",
    "b3 = np.split(b3,10)\n",
    "b4 = np.split(b4,10)\n",
    "b5 = np.split(b5,10)\n",
    "b6 = np.split(b6,10)\n",
    "\n",
    "\n",
    "# image classification\n",
    "owt_image = {}\n",
    "for x in range(0,10):\n",
    "    owt_chunck = SVMC_image_classification(b2[x],\n",
    "                                          b3[x],\n",
    "                                          b4[x],\n",
    "                                          b5[x],\n",
    "                                          b6[x],\n",
    "                                           novelty=True,\n",
    "                                          retrieve_prob=True)\n",
    "\n",
    "    owt_image[x] = owt_chunck\n",
    "    owt_chunck = None\n",
    "\n",
    "owt_image = np.concatenate((owt_image[0],\n",
    "                            owt_image[1],\n",
    "                            owt_image[2],\n",
    "                            owt_image[3],\n",
    "                            owt_image[4],\n",
    "                            owt_image[5],\n",
    "                            owt_image[6],\n",
    "                            owt_image[7],\n",
    "                            owt_image[8],\n",
    "                            owt_image[9],), axis=0)\n",
    "\n",
    "\n",
    "img_ref = gdal.Open(path+'/'+img, GA_ReadOnly)\n",
    "\n",
    "geotransform = img_ref.GetGeoTransform()\n",
    "proj = img_ref.GetProjection()\n",
    "\n",
    "\n",
    "array_to_image(owt_image,\n",
    "               img.split('/')[-1].split('.')[0].split('B2')[0]+'owt_prob_values.tif',\n",
    "               owt_path,\n",
    "               geotransform,\n",
    "               proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "404.219px",
    "left": "1668.63px",
    "right": "20px",
    "top": "123.969px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
